{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3505fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 09:07:32.904556: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 09:07:33.088309: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 09:07:33.088384: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 09:07:33.115031: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 09:07:33.177386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 09:07:33.837465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sklearn\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1024\"\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "import lightgbm\n",
    "from sklearn import ensemble\n",
    "from sklearn import dummy\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neural_network\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.fixes import loguniform\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy, gc\n",
    "import argparse\n",
    "from evaluate import load\n",
    "from features_utils import supervised_learning_steps, save_model, load_model, calculate_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d92fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_metric,roc_metric,acc_metric,mcc_metric,prec_metric,rec_metric = load(\"f1\"),load(\"roc_auc\"),load(\"accuracy\"),load(\"matthews_correlation\"),load(\"precision\"),load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return mcc_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def full_compute_metrics(predictions,labels):\n",
    "    #predictions = np.argmax(predictions, axis=1)\n",
    "    return([f1_metric.compute(predictions=predictions, references=labels),\\\n",
    "            roc_metric.compute(prediction_scores=predictions, references=labels),\\\n",
    "            acc_metric.compute(predictions=predictions, references=labels),\\\n",
    "            mcc_metric.compute(predictions=predictions, references=labels),\\\n",
    "            prec_metric.compute(predictions=predictions, references=labels),\\\n",
    "            rec_metric.compute(predictions=predictions, references=labels)])\n",
    "\n",
    "def get_CV_results (model, X_train, Y_train, n_splits):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    f1_list, roc_list, acc_list, mcc_list, prec_list, rec_list = [],[],[],[],[],[]\n",
    "    for train_index, test_index in kf.split(Y_train):\n",
    "        y_pred = model.best_estimator_.predict(X_train.iloc[test_index,:])\n",
    "        results=full_compute_metrics(y_pred,Y_train[test_index])\n",
    "        print(results)\n",
    "        f1_list.append(results[0]['f1'])\n",
    "        roc_list.append(results[1]['roc_auc'])\n",
    "        acc_list.append(results[2]['accuracy'])\n",
    "        mcc_list.append(results[3]['matthews_correlation'])\n",
    "        prec_list.append(results[4]['precision'])\n",
    "        rec_list.append(results[5]['recall'])\n",
    "    mean_f1, sd_f1 = round(np.mean(f1_list),3), round(np.std(f1_list),3)\n",
    "    mean_roc, sd_roc = round(np.mean(roc_list),3), round(np.std(roc_list),3)\n",
    "    mean_acc, sd_acc = round(np.mean(acc_list),3), round(np.std(acc_list),3)\n",
    "    mean_mcc, sd_mcc = round(np.mean(mcc_list),3), round(np.std(mcc_list),3)\n",
    "    mean_prec, sd_prec = round(np.mean(prec_list),3), round(np.std(prec_list),3)\n",
    "    mean_rec, sd_rec = round(np.mean(rec_list),3), round(np.std(rec_list),3)\n",
    "    return(mean_f1, sd_f1, mean_roc, sd_roc, mean_acc, sd_acc, mean_mcc, sd_mcc, mean_prec, sd_prec, mean_rec, sd_rec)\n",
    "\n",
    "\n",
    "# Reduce memory usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'floWith 47 new citations, your research items were the most cited research items from your institution last monthat16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':  # for integers\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:  # for floats.\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42bfee5",
   "metadata": {},
   "source": [
    "## Making the data compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04eb6bb3-6e6f-4639-9071-0b38f2a29837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed_0</th>\n",
       "      <th>allele</th>\n",
       "      <th>peptide</th>\n",
       "      <th>measurement_value</th>\n",
       "      <th>measurement_inequality</th>\n",
       "      <th>hla_sequence</th>\n",
       "      <th>category</th>\n",
       "      <th>Normalized_nM</th>\n",
       "      <th>label</th>\n",
       "      <th>peptide_id</th>\n",
       "      <th>...</th>\n",
       "      <th>boman_y</th>\n",
       "      <th>hydrophobicity_y</th>\n",
       "      <th>charge_y</th>\n",
       "      <th>molecular_weight_y</th>\n",
       "      <th>aliphatic_index_y</th>\n",
       "      <th>instability_index_y</th>\n",
       "      <th>structural_class_y</th>\n",
       "      <th>Locus</th>\n",
       "      <th>peptide_length</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>AAAALGRAP</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.997981</td>\n",
       "      <td>796.92474</td>\n",
       "      <td>98.888889</td>\n",
       "      <td>30.288889</td>\n",
       "      <td>alpha_beta</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>AAAGGGGGGGRY</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>0.997131</td>\n",
       "      <td>949.97844</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>beta</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>AAAHTHRY</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>1.178949</td>\n",
       "      <td>926.00244</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>-20.712500</td>\n",
       "      <td>alpha</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>AADAVTGRTEEY</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>positive</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.677500</td>\n",
       "      <td>-0.708333</td>\n",
       "      <td>-1.998873</td>\n",
       "      <td>1282.32944</td>\n",
       "      <td>49.166667</td>\n",
       "      <td>31.158333</td>\n",
       "      <td>alpha_beta</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>AADDYNRIGSSLY</td>\n",
       "      <td>100.0</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.574375</td>\n",
       "      <td>positive</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.436923</td>\n",
       "      <td>-0.592308</td>\n",
       "      <td>-1.002827</td>\n",
       "      <td>1444.52044</td>\n",
       "      <td>75.384615</td>\n",
       "      <td>17.515385</td>\n",
       "      <td>alpha_beta</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed_0       allele        peptide  measurement_value  \\\n",
       "0          0  HLA-A*01:01      AAAALGRAP              100.0   \n",
       "1          1  HLA-A*01:01   AAAGGGGGGGRY              100.0   \n",
       "2          2  HLA-A*01:01       AAAHTHRY              100.0   \n",
       "3          3  HLA-A*01:01   AADAVTGRTEEY              100.0   \n",
       "4          4  HLA-A*01:01  AADDYNRIGSSLY              100.0   \n",
       "\n",
       "  measurement_inequality                        hla_sequence  category  \\\n",
       "0                      <  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  positive   \n",
       "1                      <  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  positive   \n",
       "2                      <  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  positive   \n",
       "3                      <  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  positive   \n",
       "4                      <  YFAMYQENMAHTDANTLYIIYRDYTWVARVYRGY  positive   \n",
       "\n",
       "   Normalized_nM     label  peptide_id  ...   boman_y  hydrophobicity_y  \\\n",
       "0       0.574375  positive           0  ...  0.001111          0.700000   \n",
       "1       0.574375  positive           1  ...  0.254167         -0.266667   \n",
       "2       0.574375  positive           2  ...  2.690000         -0.937500   \n",
       "3       0.574375  positive           3  ...  2.677500         -0.708333   \n",
       "4       0.574375  positive           4  ...  2.436923         -0.592308   \n",
       "\n",
       "   charge_y  molecular_weight_y  aliphatic_index_y  instability_index_y  \\\n",
       "0  0.997981           796.92474          98.888889            30.288889   \n",
       "1  0.997131           949.97844          25.000000            64.583333   \n",
       "2  1.178949           926.00244          37.500000           -20.712500   \n",
       "3 -1.998873          1282.32944          49.166667            31.158333   \n",
       "4 -1.002827          1444.52044          75.384615            17.515385   \n",
       "\n",
       "   structural_class_y  Locus  peptide_length  true_label  \n",
       "0          alpha_beta      A               9           1  \n",
       "1                beta      A              12           1  \n",
       "2               alpha      A               8           1  \n",
       "3          alpha_beta      A              12           1  \n",
       "4          alpha_beta      A              13           1  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading training file\")\n",
    "data = pd.read_csv(\"/home/hamdaalhosani/Desktop/features-pHLA-main/Data/big_train_sample.csv\")\n",
    "data = data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '_', x))\n",
    "total_length = len(data.columns)\n",
    "data['true_label'] = data['label'].replace({'positive': 1, 'negative': 0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb706a48-1ec4-4cee-ab28-672d3f75d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data\n",
      "Index(['BLOSUM1_x', 'BLOSUM2_x', 'BLOSUM3_x', 'BLOSUM4_x', 'BLOSUM5_x',\n",
      "       'BLOSUM6_x', 'BLOSUM7_x', 'BLOSUM8_x', 'BLOSUM9_x', 'BLOSUM10_x',\n",
      "       ...\n",
      "       'Z3_y', 'Z4_y', 'Z5_y', 'boman_y', 'hydrophobicity_y', 'charge_y',\n",
      "       'molecular_weight_y', 'aliphatic_index_y', 'instability_index_y',\n",
      "       'structural_class_y'],\n",
      "      dtype='object', length=194)\n",
      "Getting numerical and categorical features\n",
      "['BLOSUM1_x', 'BLOSUM2_x', 'BLOSUM3_x', 'BLOSUM4_x', 'BLOSUM5_x', 'BLOSUM6_x', 'BLOSUM7_x', 'BLOSUM8_x', 'BLOSUM9_x', 'BLOSUM10_x', 'PP1_x', 'PP2_x', 'PP3_x', 'F1_x', 'F2_x', 'F3_x', 'F4_x', 'F5_x', 'F6_x', 'KF1_x', 'KF2_x', 'KF3_x', 'KF4_x', 'KF5_x', 'KF6_x', 'KF7_x', 'KF8_x', 'KF9_x', 'KF10_x', 'MSWHIM1_x', 'MSWHIM2_x', 'MSWHIM3_x', 'E1_x', 'E2_x', 'E3_x', 'E4_x', 'E5_x', 'PD1_x', 'PD2_x', 'ProtFP1_x', 'ProtFP2_x', 'ProtFP3_x', 'ProtFP4_x', 'ProtFP5_x', 'ProtFP6_x', 'ProtFP7_x', 'ProtFP8_x', 'SV1_x', 'SV2_x', 'SV3_x', 'SV4_x', 'ST1_x', 'ST2_x', 'ST3_x', 'ST4_x', 'ST5_x', 'ST6_x', 'ST7_x', 'ST8_x', 'SVGER1_x', 'SVGER2_x', 'SVGER3_x', 'SVGER4_x', 'SVGER5_x', 'SVGER6_x', 'SVGER7_x', 'SVGER8_x', 'SVGER9_x', 'SVGER10_x', 'SVGER11_x', 'T1_x', 'T2_x', 'T3_x', 'T4_x', 'T5_x', 'VHSE1_x', 'VHSE2_x', 'VHSE3_x', 'VHSE4_x', 'VHSE5_x', 'VHSE6_x', 'VHSE7_x', 'VHSE8_x', 'Z1_x', 'Z2_x', 'Z3_x', 'Z4_x', 'Z5_x', 'boman_x', 'hydrophobicity_x', 'charge_x', 'molecular_weight_x', 'aliphatic_index_x', 'instability_index_x', 'N_terminal_Hydrophobicity', 'C_terminal_Hydrophobicity', 'BLOSUM1_y', 'BLOSUM2_y', 'BLOSUM3_y', 'BLOSUM4_y', 'BLOSUM5_y', 'BLOSUM6_y', 'BLOSUM7_y', 'BLOSUM8_y', 'BLOSUM9_y', 'BLOSUM10_y', 'PP1_y', 'PP2_y', 'PP3_y', 'F1_y', 'F2_y', 'F3_y', 'F4_y', 'F5_y', 'F6_y', 'KF1_y', 'KF2_y', 'KF3_y', 'KF4_y', 'KF5_y', 'KF6_y', 'KF7_y', 'KF8_y', 'KF9_y', 'KF10_y', 'MSWHIM1_y', 'MSWHIM2_y', 'MSWHIM3_y', 'E1_y', 'E2_y', 'E3_y', 'E4_y', 'E5_y', 'PD1_y', 'PD2_y', 'ProtFP1_y', 'ProtFP2_y', 'ProtFP3_y', 'ProtFP4_y', 'ProtFP5_y', 'ProtFP6_y', 'ProtFP7_y', 'ProtFP8_y', 'SV1_y', 'SV2_y', 'SV3_y', 'SV4_y', 'ST1_y', 'ST2_y', 'ST3_y', 'ST4_y', 'ST5_y', 'ST6_y', 'ST7_y', 'ST8_y', 'SVGER1_y', 'SVGER2_y', 'SVGER3_y', 'SVGER4_y', 'SVGER5_y', 'SVGER6_y', 'SVGER7_y', 'SVGER8_y', 'SVGER9_y', 'SVGER10_y', 'SVGER11_y', 'T1_y', 'T2_y', 'T3_y', 'T4_y', 'T5_y', 'VHSE1_y', 'VHSE2_y', 'VHSE3_y', 'VHSE4_y', 'VHSE5_y', 'VHSE6_y', 'VHSE7_y', 'VHSE8_y', 'Z1_y', 'Z2_y', 'Z3_y', 'Z4_y', 'Z5_y', 'boman_y', 'hydrophobicity_y', 'charge_y', 'molecular_weight_y', 'aliphatic_index_y', 'instability_index_y']\n",
      "Identified categorical features\n",
      "['structural_class_x', 'N_terminal', 'C_terminal', 'structural_class_y']\n",
      "Setting up preprocessing steps...\n",
      "Pipeline Created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5794/2130478357.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:,\"N_terminal_Hydrophobicity\"] = X_train.loc[:,\"N_terminal_Hydrophobicity\"].fillna(0)\n",
      "/tmp/ipykernel_5794/2130478357.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:,\"C_terminal_Hydrophobicity\"] = X_train.loc[:,\"C_terminal_Hydrophobicity\"].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "#Consider only those columns which have numeric values\n",
    "print(\"Processing training data\")\n",
    "metadata_X, X_train, Y_train = data.loc[:,[\"Unnamed_0\",\"allele\",\"peptide\",\"measurement_value\",\"measurement_inequality\",\"hla_sequence\",\"category\",\"Normalized_nM\",\"peptide_id\",\"Locus\",\"peptide_length\",\"label\",\"allele_id\"]], data.iloc[:,range(11,205)], data[\"true_label\"].to_numpy().flatten()\n",
    "print(X_train.columns)\n",
    "\n",
    "#Get all numeric and categorical columns\n",
    "print(\"Getting numerical and categorical features\")\n",
    "all_numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numerical_features = [col for col in all_numerical_cols]\n",
    "print(numerical_features)\n",
    "\n",
    "all_categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "categorical_features = [col for col in all_categorical_cols]\n",
    "print(\"Identified categorical features\")\n",
    "print(categorical_features)\n",
    "\n",
    "#Replace few rows with missing values with 0\n",
    "X_train.loc[:,\"N_terminal_Hydrophobicity\"] = X_train.loc[:,\"N_terminal_Hydrophobicity\"].fillna(0)\n",
    "X_train.loc[:,\"C_terminal_Hydrophobicity\"] = X_train.loc[:,\"C_terminal_Hydrophobicity\"].fillna(0)\n",
    "\n",
    "# Setting up preprocessing steps\n",
    "numerical_imputer = SimpleImputer(strategy='median')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "print(\"Setting up preprocessing steps...\")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Perform preprocessing\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "print(\"Pipeline Created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8459c3dd-8dfc-4d01-993d-15c7a91f77f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed\n",
      "Shape of training set after removing non-numeric cols\n",
      "(661192, 239)\n",
      "[]\n",
      "Mem. usage decreased to 301.41 Mb (75.0% reduction)\n",
      "Shape of training set after removing cols with NaNs\n",
      "(661192, 239)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data\n",
    "X_train_processed = pd.DataFrame(pipeline.fit_transform(X_train))\n",
    "categorical_feature_names = pipeline.named_steps['preprocessor'].transformers_[1][1]\\\n",
    "                                    .named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "all_feature_names = list(numerical_features) + list(categorical_feature_names)\n",
    "X_train_processed.columns = all_feature_names\n",
    "print(\"Data processed\")\n",
    "\n",
    "#Keep only numeric training and test set and those which have no Nans\n",
    "X_train_numerics_only = X_train_processed.select_dtypes(include=np.number)\n",
    "print(\"Shape of training set after removing non-numeric cols\")\n",
    "print(X_train_numerics_only.shape)\n",
    "\n",
    "#Remove columns with Nan values\n",
    "nan_cols = [i for i in X_train_numerics_only.columns if X_train_numerics_only[i].isnull().any()]\n",
    "column_names = X_train_numerics_only.columns.values.tolist()\n",
    "print(nan_cols)\n",
    "\n",
    "#Change floating points to reduce size of data\n",
    "rev_X_train = X_train_numerics_only.drop(nan_cols,axis=1)\n",
    "rev_X_train_o   = reduce_mem_usage(rev_X_train)\n",
    "print(\"Shape of training set after removing cols with NaNs\")\n",
    "print(rev_X_train_o.shape)\n",
    "\n",
    "del X_train\n",
    "del X_train_processed\n",
    "del X_train_numerics_only\n",
    "del rev_X_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f97ead8-a5cc-4ef8-ab57-f9b7acf39f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the LightGBM Regression model\n",
    "lgbm_model = lightgbm.LGBMClassifier(boosting_type='gbdt',random_state=0, n_jobs=1, objective=\"binary\", class_weight=\"balanced\")\n",
    "\n",
    "# Grid parameters\n",
    "params_lgbm = {\n",
    "        \"n_estimators\": scipy.stats.randint(20, 500),\n",
    "        \"max_depth\": scipy.stats.randint(3, 7),\n",
    "        \"num_leaves\": [16, 32, 64, 128],\n",
    "        \"min_child_samples\": scipy.stats.randint(5, 20),\n",
    "        \"learning_rate\": loguniform(1e-4, 1e-1),\n",
    "        \"subsample\": loguniform(0.8, 1e0),\n",
    "        \"colsample_bytree\": [0.1, 0.3, 0.5, 0.7],\n",
    "        \"reg_alpha\": loguniform(1e-1, 1e1),\n",
    "        \"reg_lambda\": loguniform(1, 1e1),\n",
    "        \"verbose\": [-1]\n",
    "    }\n",
    "    \n",
    "##It will select 200 random combinations for the CV and do 5-fold CV for each combinationimport peptides\n",
    "#n_iter = 100\n",
    "#lgbm_gs=supervised_learning_steps(\"lgbm\",\"f1\",\"NC_binary\",True,lgbm_model,params_lgbm,\\\n",
    "#                                      rev_X_train_o,Y_train,n_iter=n_iter,n_splits=5)\n",
    "\n",
    "#lgbm_best = lgbm_gs.best_estimator_\n",
    "\n",
    "##Save the preprocessor\n",
    "#save_model(pipeline,\"processor.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3685a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best = lgbm_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5647e6c0-2b6b-42e0-8270-c0ce2e028a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model to file: ../Models/lgbm_models/lgbm_NC_binary_classifier_gs.pk\n",
      "[{'f1': 0.849418715339405}, {'roc_auc': 0.8450560790935603}, {'accuracy': 0.8145857122331536}, {'matthews_correlation': 0.6435887717515425}, {'precision': 0.9580510646551127}, {'recall': 0.7629128698453324}]\n",
      "[{'f1': 0.89865642314705}, {'roc_auc': 0.8937929547551113}, {'accuracy': 0.8701215223950575}, {'matthews_correlation': 0.7391627541425837}, {'precision': 0.9767200246267508}, {'recall': 0.8321476576074485}]\n",
      "[{'f1': 0.9582156414731122}, {'roc_auc': 0.9040137756870402}, {'accuracy': 0.9297478788245436}, {'matthews_correlation': 0.7437518300340455}, {'precision': 0.9770776004402861}, {'recall': 0.9400681304716182}]\n",
      "[{'f1': 0.962172474171865}, {'roc_auc': 0.9172755599331821}, {'accuracy': 0.9361227483779246}, {'matthews_correlation': 0.7637956396690604}, {'precision': 0.9817410852996545}, {'recall': 0.9433687223934596}]\n",
      "[{'f1': 0.9779194210331934}, {'roc_auc': 0.9293959853896415}, {'accuracy': 0.9597619443730244}, {'matthews_correlation': 0.7601531325802645}, {'precision': 0.9908925012404026}, {'recall': 0.9652816462955074}]\n",
      "(0.929, 0.048, 0.898, 0.029, 0.902, 0.053, 0.73, 0.044, 0.977, 0.011, 0.889, 0.078)\n"
     ]
    }
   ],
   "source": [
    "lgbm_gs = load_model(\"lgbm_models/lgbm_NC_binary_classifier_gs.pk\")\n",
    "results = get_CV_results(lgbm_gs,rev_X_train_o,Y_train,n_splits=5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd264ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'f1': 0.7573854627388801}, {'roc_auc': 0.767629107739849}, {'accuracy': 0.7682704474578298}, {'matthews_correlation': 0.5358042351021143}, {'precision': 0.7664843865464603}, {'recall': 0.7485000309271974}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147690/4271232351.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_X_test['predictions']=y_pred_lgbm\n",
      "/tmp/ipykernel_147690/4271232351.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metadata_X_test['labels']=Y_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing predictions\n"
     ]
    }
   ],
   "source": [
    "#Load the external test set\n",
    "external_5allele_data = pd.read_csv(\"../../Data/external_set_5_allele.csv\",header='infer')\n",
    "external_5allele_data = external_5allele_data.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '_', x))\n",
    "external_5allele_data['true_label'] = external_5allele_data['label'].replace({'positive': 1, 'negative': 0})\n",
    "rev_external_5allele_data = external_5allele_data.drop([\"allele\",\"peptide\",\"hla_sequence\",\"Normalized_nM\",\"peptide_id\",\"allele_id\",\"measurement_value\",\"measurement_inequality\",\"category\",\"peptide_length\",\"Locus\",\"label\"],axis=1)\n",
    "\n",
    "rev_X_test = pd.DataFrame(pipeline.transform(rev_external_5allele_data))\n",
    "rev_X_test.columns = list(numerical_features) + list(categorical_feature_names)\n",
    "rev_X_test.shape\n",
    "\n",
    "Y_test = rev_external_5allele_data['true_label'].to_numpy().tolist()\n",
    "\n",
    "#Get the predictions\n",
    "lgbm_best = lgbm_gs.best_estimator_\n",
    "y_pred_lgbm=lgbm_best.predict(rev_X_test)\n",
    "test_metrics=full_compute_metrics(y_pred_lgbm,Y_test)\n",
    "print(test_metrics)\n",
    "\n",
    "metadata_X_test = external_5allele_data[[\"allele\",\"peptide\",\"hla_sequence\",\"allele_id\",\"peptide_id\",\"Locus\",\"peptide_length\"]]\n",
    "metadata_X_test['predictions']=y_pred_lgbm\n",
    "metadata_X_test['labels']=Y_test\n",
    "metadata_X_test.to_csv(\"../Results/LGBM_NC_binary_supervised_external_predictions.csv\",index=False,sep=\"\\t\")\n",
    "print(\"Finished writing predictions\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
